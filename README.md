## 🦙 Ollama Wall

> *“Oops. I left my LLaMA running wide open…”* — Someone, probably.

**Ollama Wall** is a passive AI security dashboard that highlights one simple, overlooked fact:

> A surprising number of people have accidentally exposed their Ollama servers to the entire internet — no auth, no firewall, just... vibes.

This project:

* Doesn’t hack
* Doesn’t probe
* Doesn’t even look at you funny 👀
* Just listens to what’s already shouting into the void

It just politely points out that maybe, just maybe, running a multimodal LLM on your servers without authentication is a bad idea.

---

## 🎯 What It Shows

* 🟢 Servers that are online and leaking models
* 🟡 Servers that are online but empty
* 🔴 Servers that were once open, now offline or secured

Each one is masked, sanitized, and ~~rate-limited~~. No servers were harmed in the making of this wall.

---

## 🧠 Why It Exists

This is not a burn board.

It’s a public security awareness project designed to:

* Show the unintended side of AI deployment
* Encourage better defaults in open-source tools
* Spark conversation about where model hosting meets cybersecurity

No scans. No leaks. Just redacted reality.

---

## 🤝 Want to Help?

* 🛡️ **Run Ollama securely** — auth on, ports closed
* 📣 **Share this project** with AI developers and teams
* 🧑‍💻 **Open an issue or PR** with suggestions or feedback
* 📬 **Or just admire the llamas**

Security starts with awareness — and sometimes that starts with a llama on the internet.

---