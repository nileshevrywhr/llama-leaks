## ğŸ¦™ LLaMa Leaks

> *â€œOops. I left my LLaMA running wide openâ€¦â€* â€” Someone, probably.

**LLaMa Leaks** is a passive AI security dashboard that highlights one simple, overlooked fact:

> A surprising number of people have accidentally exposed their Ollama servers to the entire internet â€” no auth, no firewall, just... vibes.

This project:

* Doesnâ€™t hack
* Doesnâ€™t probe
* Doesnâ€™t even look at you funny ğŸ‘€
* Just listens to whatâ€™s already shouting into the void

It just politely points out that maybe, just maybe, running a multimodal LLM on your servers without authentication is a bad idea.

---

## ğŸ¯ What It Shows

* ğŸŸ¢ Servers that are online and leaking models
* ğŸŸ¡ Servers that are online but empty
* ğŸ”´ Servers that were once open, now offline or secured

Each one is masked, sanitized, and ~~rate-limited~~. No servers were harmed in the making of this wall.

---

## ğŸ§  Why It Exists

This is not a burn board.

Itâ€™s a public security awareness project designed to:

* Show the unintended side of AI deployment
* Encourage better defaults in open-source tools
* Spark conversation about where model hosting meets cybersecurity

No scans. No leaks. Just redacted reality.

---

## ğŸ¤ Want to Help?

* ğŸ›¡ï¸ **Run Ollama securely** â€” auth on, ports closed
* ğŸ“£ **Share this project** with AI developers and teams
* ğŸ§‘â€ğŸ’» **Open an issue or PR** with suggestions or feedback
* ğŸ“¬ **Or just admire the llamas**

Security starts with awareness â€” and sometimes that starts with a llama on the internet.

---
